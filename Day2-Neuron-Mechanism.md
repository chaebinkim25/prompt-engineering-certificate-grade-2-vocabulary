# 📘 Day 2. 뉴런의 작동 원리

> **목표**  
> 컴퓨터가 “생각하는 것처럼 보이게” 만드는 가장 기본 단위인  
> **뉴런과 활성화 함수**의 역할을 이해한다.  
> (수식보다 **개념과 흐름** 중심)

---
## 1️⃣ Neuron (뉴런)


### 한 문장 요약
**뉴런은 여러 숫자를 받아서 중요도를 반영해 하나의 숫자를 만들어 내는 작은 계산기다.**

### 쉽게 설명하면
- 사람 뇌의 신경세포에서 **아이디어만 빌려온 구조**
- 실제로는 생각하지 않고 **계산만 수행**

### 뉴런이 하는 일 (3단계)
1. 여러 입력값을 받는다  
2. 각 입력에 “얼마나 중요한지”를 곱한다  
3. 모두 더해서 하나의 결과를 만든다  

> 이 결과가 다음 뉴런으로 전달될지, 말지가 결정된다.

📌 **중요**
- 뉴런 하나는 아주 단순하다  
- 하지만 이것을 **엄청 많이 연결**하면  
  → 판단하는 것처럼 보이게 된다

---

## 2️⃣ Activation Function (활성화 함수)


### 한 문장 요약
**활성화 함수는 뉴런의 계산 결과를 다음 단계로 보낼지 말지 정하는 규칙이다.**

### 왜 필요한가?
- 뉴런 계산 결과는 그냥 숫자일 뿐이다
- 모든 숫자를 그대로 넘기면  
  → 신경망은 단순한 계산기에서 벗어나지 못한다

### 활성화 함수의 역할
- 의미 없는 값 → 줄이거나 버림  
- 의미 있는 값 → 강조해서 전달  

📌 활성화 함수가 없으면  
→ 딥러닝은 **절대 똑똑해질 수 없다**

---

## 3️⃣ Sigmoid (시그모이드)


### 한 문장 요약
**Sigmoid는 어떤 숫자든 0과 1 사이의 값으로 눌러주는 함수다.**

### 직관적인 이해
- 결과가 1에 가까우면 → “그럴 가능성 큼”
- 결과가 0에 가까우면 → “그럴 가능성 작음”

### 사용 예
- 예/아니오 판단  
- 참/거짓 분류  
- 스팸 메일 판단 등

📌 단점
- 값이 너무 크거나 작아지면  
  → 변화가 거의 멈춤  
  → 학습이 느려진다

---

## 4️⃣ ReLU (렐루)


### 한 문장 요약
**ReLU는 0보다 작은 값은 버리고, 0보다 큰 값만 그대로 사용하는 함수다.**

### 규칙을 말로 쓰면
- 입력값 ≤ 0 → 0  
- 입력값 > 0 → 그대로 사용  

### 왜 많이 쓰일까?
- 계산이 매우 빠르다  
- 학습이 잘 된다  
- 구조가 단순하다  

📌 **현재 딥러닝의 기본 선택**

⚠️ 단점
- 어떤 뉴런은 계속 0만 나와서  
  → 완전히 역할을 못 하게 될 수도 있다

---

## 5️⃣ Tanh (탄에이치)


### 한 문장 요약
**Tanh는 결과를 -1에서 1 사이로 압축하는 함수다.**

### Sigmoid와의 차이
- Sigmoid → 0 ~ 1  
- Tanh → **-1 ~ 1**

### 장점
- 값의 방향(증가 / 감소)을 표현할 수 있다
- 중심이 0이라서 균형 잡힌 표현에 유리

📌 단점
- Sigmoid와 마찬가지로  
  → 값이 커지면 학습이 둔해진다

---

## 6️⃣ Softmax (소프트맥스)


### 한 문장 요약
**Softmax는 여러 결과를 확률처럼 보이게 바꿔주는 함수다.**

### 예시
사진 하나를 보고:
- 고양이: 70%  
- 강아지: 20%  
- 토끼: 10%  

→ 모든 값의 합 = **100%**

### 언제 사용하나?
- 여러 선택지 중 하나를 고르는 문제
- 분류 문제의 **마지막 단계**

---

## 🧠 Day 2 핵심 요약

| 용어 | 핵심 의미 |
|---|---|
| Neuron | 숫자를 받아 하나의 숫자를 만드는 계산 단위 |
| Activation Function | 결과를 쓸지 말지 정하는 규칙 |
| Sigmoid | 0~1로 압축 (예/아니오 판단) |
| ReLU | 음수 제거, 양수 통과 (가장 많이 사용) |
| Tanh | -1~1로 압축 (방향성 표현) |
| Softmax | 여러 결과를 확률처럼 변환 |

---

➡️ **다음 Day 3 예고**  
> “이 계산기들이 어떻게 틀리면서도 점점 똑똑해지는가?”  
> **오차, 손실, 그리고 고치는 방법**으로 넘어간다.
